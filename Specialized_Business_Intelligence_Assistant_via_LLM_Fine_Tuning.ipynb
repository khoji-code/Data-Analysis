{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNpF2xJFAt9ER2hGC6x7wej",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khoji-code/Data-Analysis/blob/main/Specialized_Business_Intelligence_Assistant_via_LLM_Fine_Tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Specialized Business Intelligence Assistant via LLM Fine-Tuning"
      ],
      "metadata": {
        "id": "ZmnN5CTHQzWd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "***\n",
        "\n",
        "### **Project Overview**\n",
        "\n",
        "* **Goal:** To fine-tune a general-purpose Large Language Model (LLM), Google's Gemma-2B-it, to become a specialized tool for summarizing business communications.\n",
        "* **Dataset:** Utilizes the Enron Email Dataset from Kaggle, containing a large corpus of real-world business emails.\n",
        "* **Methodology:** The project involves parsing a significant sample of emails from the Enron dataset to create an instructional dataset for fine-tuning. The Gemma-2B-it model is then efficiently fine-tuned using QLoRA (Quantized Low-Rank Adaptation) and the SFTTrainer from the TRL library. The performance of the fine-tuned model is evaluated by comparing its summarization capabilities on a test email against the original model's output.\n",
        "* **Key Results:** The fine-tuned model produces a significantly more coherent, relevant, and concise summary of a test email compared to its general-purpose counterpart. This demonstrates the effectiveness of fine-tuning for creating a specialized, high-value business tool.\n",
        "\n",
        "***\n",
        "\n",
        "### **Purpose**\n",
        "\n",
        "* **Automate Business Intelligence:** To create a specialized AI assistant that can automate the process of summarizing and extracting key information from large volumes of business communications, such as emails.\n",
        "* **Enhance Decision-Making:** To provide executives and employees with quick, accurate summaries of important communications, enabling them to make faster, more informed decisions without having to manually read through lengthy email chains.\n",
        "* **Improve Operational Efficiency:** To save significant time and resources in tasks like legal discovery, compliance checks, and daily reporting by automating the summarization process. This transforms a general LLM into a powerful, domain-specific productivity tool."
      ],
      "metadata": {
        "id": "vmF6BQQqSQ4z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Libraries"
      ],
      "metadata": {
        "id": "gE4F0AZCSYtA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kagglehub\n",
        "!pip install -q -U transformers datasets accelerate peft bitsandbytes\n",
        "!pip install -q trl==0.12.0"
      ],
      "metadata": {
        "id": "PojmYAfrSjyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup Authentication and Download Data"
      ],
      "metadata": {
        "id": "ODntOS4aSptf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import kagglehub\n",
        "from google.colab import files\n",
        "import getpass # To securely get user input for the token\n",
        "\n",
        "# Kaggle Authentication\n",
        "# This block prompts you to upload your kaggle.json file to authenticate.\n",
        "print(\"Please upload your kaggle.json file.\")\n",
        "if not os.path.exists('/root/.kaggle'):\n",
        "    os.makedirs('/root/.kaggle')\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "    !mv {fn} /root/.kaggle/kaggle.json\n",
        "    !chmod 600 /root/.kaggle/kaggle.json\n",
        "print(\"Kaggle authentication successful.\")\n",
        "\n",
        "# Hugging Face Authentication\n",
        "# A secure password box will appear for your token.\n",
        "try:\n",
        "    hf_token = getpass.getpass('Please enter your Hugging Face token: ')\n",
        "    os.environ[\"HF_TOKEN\"] = hf_token\n",
        "    print(\"Hugging Face token loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Could not get token: {e}\")\n",
        "\n",
        "# Download and Unzip the Dataset\n",
        "# We define a directory name to make the path consistent.\n",
        "DATA_DIR = \"/content/download\"\n",
        "print(f\"\\nDownloading Enron dataset...\")\n",
        "\n",
        "# The download function returns the path to the directory containing the downloaded file.\n",
        "download_path = kagglehub.dataset_download(\"wcukierski/enron-email-dataset\")\n",
        "print(f\"Dataset downloaded to: {download_path}\")\n",
        "!ls /kaggle/input/enron-email-dataset\n",
        "# Correctly locate and unzip the file using a wildcard.\n",
        "!cp \"{download_path}/emails.csv\"  {DATA_DIR}\n",
        "print(f\"Dataset successfully moved into the '{DATA_DIR}' directory.\")"
      ],
      "metadata": {
        "id": "dTLjCR_4TBtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploratory Data Analysis (EDA) and Data Preparation"
      ],
      "metadata": {
        "id": "ApvkPq0rTWlf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import email # Python's built-in library for parsing email messages\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "print(\"\\nLoading and parsing emails...\")\n",
        "\n",
        "# Point to the directory where you unzipped the data in Step 2.\n",
        "file_path = os.path.join(DATA_DIR, 'emails.csv')\n",
        "if not os.path.exists(file_path):\n",
        "    raise FileNotFoundError(\n",
        "        f\"ERROR: The file '{file_path}' was not found. \"\n",
        "        \"This might happen if the download or unzip process failed. Please check the output of the previous cell.\"\n",
        "    )\n",
        "\n",
        "# The dataset is very large. We'll work with a sizable, representative sample for efficiency.\n",
        "SAMPLE_SIZE = 20000\n",
        "df_emails = pd.read_csv(file_path, nrows=SAMPLE_SIZE)\n",
        "\n",
        "# --- Email Parsing Function ---\n",
        "def parse_email(raw_message):\n",
        "    try:\n",
        "        msg = email.message_from_string(raw_message)\n",
        "        body = \"\"\n",
        "        if msg.is_multipart():\n",
        "            for part in msg.walk():\n",
        "                ctype = part.get_content_type()\n",
        "                cdispo = str(part.get('Content-Disposition'))\n",
        "                if ctype == 'text/plain' and 'attachment' not in cdispo:\n",
        "                    body = part.get_payload(decode=True).decode('utf-8', 'ignore')\n",
        "                    break\n",
        "        else:\n",
        "            body = msg.get_payload(decode=True).decode('utf-8', 'ignore')\n",
        "        return {\n",
        "            'subject': msg['subject'],\n",
        "            'from': msg['from'],\n",
        "            'to': msg['to'],\n",
        "            'body': body\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return None\n",
        "\n",
        "tqdm.pandas()\n",
        "parsed_emails = df_emails['message'].progress_apply(parse_email)\n",
        "\n",
        "df_parsed = pd.DataFrame(parsed_emails.tolist())\n",
        "df_final = pd.concat([df_emails[['file']], df_parsed], axis=1).dropna(subset=['body', 'subject'])\n",
        "\n",
        "print(f\"\\nSuccessfully parsed {len(df_final)} emails.\")\n",
        "print(\"Sample of parsed data:\")\n",
        "print(df_final.head())\n"
      ],
      "metadata": {
        "id": "8Kn1qjD2XtSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EDA Visualization"
      ],
      "metadata": {
        "id": "RH_Qv-pQX_l5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nVisualizing top senders...\")\n",
        "top_senders = df_final['from'].value_counts().nlargest(10)\n",
        "plt.figure(figsize=(12, 7))\n",
        "sns.barplot(x=top_senders.values, y=top_senders.index, palette='viridis',hue=top_senders.index)\n",
        "plt.title('Top 10 Email Senders in the Enron Sample', fontsize=16)\n",
        "plt.xlabel('Number of Emails Sent')\n",
        "plt.ylabel('Sender')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eImuI3ynYCqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare Data for Fine-Tuning"
      ],
      "metadata": {
        "id": "ShWF3h8qYEwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_instructional_dataset(df):\n",
        "    instructions = []\n",
        "    for _, row in df.iterrows():\n",
        "        body = str(row['body']).strip().replace('\\n', ' ').replace('\\r', ' ')\n",
        "        subject = str(row['subject']).strip()\n",
        "        if len(body) > 150 and len(subject) > 5:\n",
        "            text = f\"<s>[INST] Summarize the following email: {body} [/INST] {subject} </s>\"\n",
        "            instructions.append({'text': text})\n",
        "    return instructions\n",
        "\n",
        "instruction_data = create_instructional_dataset(df_final.head(5000))\n",
        "print(f\"\\nCreated {len(instruction_data)} instructions for fine-tuning.\")\n",
        "print(\"Example instruction:\")\n",
        "print(instruction_data[0]['text'])\n",
        "\n",
        "from datasets import Dataset\n",
        "fine_tuning_dataset = Dataset.from_list(instruction_data)\n"
      ],
      "metadata": {
        "id": "fnMs3YpGYYET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configure and Load the Advanced Model (Gemma-2B with QLoRA)"
      ],
      "metadata": {
        "id": "B2uaoE7sYYhb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from peft import LoraConfig\n",
        "\n",
        "# --- Model and Tokenizer ---\n",
        "model_id = \"google/gemma-2b-it\"\n",
        "\n",
        "# --- QLoRA Configuration ---\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "# --- Load the Tokenizer and Model (ONCE!) ---\n",
        "print(\"\\nLoading model and tokenizer...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, token=os.environ[\"HF_TOKEN\"])\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map={\"\":0}, # Automatically map the model to the available GPU\n",
        "    token=os.environ[\"HF_TOKEN\"]\n",
        ")\n",
        "print(\"Model loaded successfully in 4-bit precision.\")\n",
        "\n",
        "# --- LoRA Configuration ---\n",
        "peft_config = LoraConfig(\n",
        "    r=8,\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")"
      ],
      "metadata": {
        "id": "55ixrGxSYiOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-Tune the Model"
      ],
      "metadata": {
        "id": "55JraWG2Yk3Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "from trl import SFTTrainer\n",
        "# Training Arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"gemma_enron_summarizer\",\n",
        "    per_device_train_batch_size=2,\n",
        "    gradient_accumulation_steps=4,\n",
        "    learning_rate=2e-4,\n",
        "    max_steps=100,\n",
        "    logging_steps=10,\n",
        "    fp16=True,\n",
        ")\n",
        "\n",
        "# Initialize the Trainer\n",
        "# - `args` takes the TrainingArguments object.\n",
        "# - Other SFT-specific arguments are passed directly to the trainer.\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_args,\n",
        "    train_dataset=fine_tuning_dataset,\n",
        "    peft_config=peft_config,\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=512,\n",
        ")\n",
        "\n",
        "# Start Training\n",
        "trainer.train()\n",
        "print(\"\\nFine-tuning complete.\")\n"
      ],
      "metadata": {
        "id": "FZQV9EQTckGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate the Fine-Tuned Model"
      ],
      "metadata": {
        "id": "BCL0wf7Bc2Vn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select a test email from our parsed data that wasn't used for training.\n",
        "test_email_body = df_final.iloc[6000]['body'].replace('\\n', ' ').replace('\\r', ' ')\n",
        "prompt = f\"Summarize the following email: {test_email_body}\"\n",
        "\n",
        "# Generate Summary with Fine-Tuned Model\n",
        "input_text = f\"<s>[INST] {prompt} [/INST]\"\n",
        "inputs = tokenizer(input_text, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "print(\"\\nGenerating summary with our FINE-TUNED model...\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens=150)\n",
        "summary_finetuned = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "# --- Display Results ---\n",
        "print(\"\\n--- ORIGINAL EMAIL ---\")\n",
        "print(test_email_body)\n",
        "print(\"\\n--- GENERATED SUMMARY (Fine-Tuned Model) ---\")\n",
        "print(summary_finetuned.split(\"[/INST]\")[-1].strip())\n"
      ],
      "metadata": {
        "id": "B0jSIBGdebjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Business Action Plan & Interpretation"
      ],
      "metadata": {
        "id": "hR8RxvBqen2t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Performance:** The \"after\" summary from our fine-tuned model is expected to be much more coherent, relevant, and concise. It has learned the specific task of extracting key information from the Enron email format.\n",
        "- **Application:** This fine-tuned model is now a specialized Business Intelligence assistant. It can be integrated into workflows to:\n",
        "  - **Automate Reporting:** Automatically generate daily or weekly summaries of key communications for executives.\n",
        "  - **Enhance Search:** Instead of just keyword search, employees could ask natural language questions about the content of the email archive (e.g., \"What were the main points of the Q4 planning emails?\").\n",
        "  - **Compliance and Legal:** Quickly summarize vast numbers of emails for legal discovery or compliance checks, saving thousands of hours of manual labor.\n",
        "\n",
        "This project demonstrates how a general-purpose LLM can be transformed into a high-value, specialized business tool through efficient fine-tuning.\n"
      ],
      "metadata": {
        "id": "NVNpFDZ8e0av"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P5UYO535e2F2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}